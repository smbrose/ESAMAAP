{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b19519",
   "metadata": {},
   "source": [
    "# Aeolus ESA MAAP Data Access Example for Aeolus L1B\n",
    "\n",
    "@ ESA, 2025\n",
    "= Licensed under \"European Space Agency Community License\" \n",
    "\n",
    "Author: Saskia Brose (saskia.brose@esa.int)\n",
    "\n",
    "Date: 18-09-2025\n",
    "\n",
    "---\n",
    "\n",
    "This script shows how to query the ESA MAAP catalog and stream/download AEOLUS data in combination with the Coda library and a reader provided by Stefanie Knobloch (04/09/2025).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217a6fe",
   "metadata": {},
   "source": [
    "### Setup CODA Definition Path and Environment Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f582311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Define the CODA definition folder version; Ensure the correct path separator is used\n",
    "codadef_version = 'codadef-aeolus-20231201'\n",
    "\n",
    "# Build the full path to the CODA definition directory: Join the current working directory and the definition folder\n",
    "codadef_path = os.path.join(os.getcwd(), codadef_version)\n",
    "\n",
    "# Check if the codadef directory exists\n",
    "if not os.path.exists(codadef_path):\n",
    "    raise FileNotFoundError(f'Archive {codadef_version} not found. Make sure '\n",
    "                            f'that the archive exists in the current working directory ...')\n",
    "\n",
    "# Set the CODA_DEFINITION environment variable\n",
    "os.environ['CODA_DEFINITION'] = codadef_path\n",
    "\n",
    "# Check if it's set correctly\n",
    "print(\"CODA_DEFINITION:\", os.getenv('CODA_DEFINITION'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa160a",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Make sure these come after you set the codadef path as an environment variable! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from numpy import hstack, vstack\n",
    "import re\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "import fsspec\n",
    "import tempfile\n",
    "import pathlib\n",
    "import coda\n",
    "import matplotlib.pyplot as plt\n",
    "from pystac_client import Client\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe8a55",
   "metadata": {},
   "source": [
    "### L1b Reader \n",
    "\n",
    "A2S products reader.\n",
    "\n",
    "@author: Stefanie Knobloch \n",
    "\n",
    "Last update: 04.09.2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a907ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1b_reader:\n",
    "    \n",
    "    def __init__(self, cf):\n",
    "        self.cf = cf\n",
    "        self.file = xr.Dataset({})\n",
    "\n",
    "    L1B_LOCATIONS = {\n",
    "        # Geolocation ---------------------------------------------------------\n",
    "        'start_of_observation_time':                ['geolocation', -1, 'start_of_observation_time'],\n",
    "        'time':                                     ['geolocation', -1, 'observation_aocs', 'observation_centroid_time'],\n",
    "        'roll_angle':                               ['geolocation', -1, 'observation_aocs', 'roll_angle'],\n",
    "        'meas_time':                                ['geolocation', -1, 'measurement_aocs',-1, 'measurement_centroid_time'],\n",
    "        'longitude_of_DEM_intersection':            ['geolocation', -1, 'observation_geolocation', 'geolocation_of_dem_intersection', 'longitude_of_dem_intersection'],\n",
    "        'latitude_of_DEM_intersection':             ['geolocation', -1, 'observation_geolocation', 'geolocation_of_dem_intersection', 'latitude_of_dem_intersection'],\n",
    "        'altitude_of_DEM_intersection':             ['geolocation', -1, 'observation_geolocation', 'geolocation_of_dem_intersection', 'altitude_of_dem_intersection'],\n",
    "        'argument_of_latitude_of_DEM_intersection': ['geolocation', -1, 'observation_geolocation', 'geolocation_of_dem_intersection', 'argument_of_latitude_of_dem_intersection'],\n",
    "        'sun_elevation_at_DEM_intersection':        ['geolocation', -1, 'observation_geolocation', 'geolocation_of_dem_intersection', 'sun_elevation_at_dem_intersection'],\n",
    "        'mie_longitude':                            ['geolocation', -1, 'observation_geolocation', 'observation_mie_geolocation', -1, 'longitude_of_height_bin'],\n",
    "        'mie_latitude':                             ['geolocation', -1, 'observation_geolocation', 'observation_mie_geolocation', -1, 'latitude_of_height_bin'],\n",
    "        'ray_longitude':                            ['geolocation', -1, 'observation_geolocation', 'observation_rayleigh_geolocation', -1, 'longitude_of_height_bin'],\n",
    "        'ray_latitude':                             ['geolocation', -1, 'observation_geolocation', 'observation_rayleigh_geolocation', -1, 'latitude_of_height_bin'],\n",
    "        'mie_altitude':                             ['geolocation', -1, 'observation_geolocation', 'observation_mie_geolocation', -1, 'altitude_of_height_bin'],\n",
    "        'ray_altitude':                             ['geolocation', -1, 'observation_geolocation', 'observation_rayleigh_geolocation', -1, 'altitude_of_height_bin'],\n",
    "        'mie_altitude_meas':                        ['geolocation', -1, 'measurement_geolocation', -1, 'mie_geolocation',-1, 'altitude_of_height_bin'],\n",
    "        'rayleigh_altitude_meas':                   ['geolocation', -1, 'measurement_geolocation', -1, 'rayleigh_geolocation',-1, 'altitude_of_height_bin'],\n",
    "        'mie_range':                                ['geolocation', -1, 'observation_geolocation', 'observation_mie_geolocation', -1, 'satellite_range_of_height_bin'],\n",
    "        'ray_range':                                ['geolocation', -1, 'observation_geolocation', 'observation_rayleigh_geolocation', -1, 'satellite_range_of_height_bin'],\n",
    "        'sun_elevation_at_DEM_intersection_meas':   ['geolocation', -1, 'measurement_geolocation', -1, 'geolocation_of_dem_intersection', 'sun_elevation_at_dem_intersection'],\n",
    "        'topocentric_elevation_of_height_bin':      ['geolocation', -1, 'observation_geolocation', 'observation_rayleigh_geolocation', -1, 'topocentric_elevation_of_height_bin'],\n",
    "        \n",
    "        # Instrument ----------------------------------------------------------\n",
    "        'mie_measurement_data':                     ['measurement', -1, 'mie_measurement_data'],\n",
    "        # 'ray_measurement_data':                     ['measurement', -1, 'rayleigh_measurement_data'],\n",
    "        'mie_useful_signal':                        ['useful_signal', -1, 'observation_useful_signals', 'mie_altitude_bin_useful_signal_info', -1, 'useful_signal'],\n",
    "        'mie_useful_signal_data_quality_flag':      ['useful_signal', -1, 'observation_useful_signals', 'mie_altitude_bin_useful_signal_info', -1, 'data_quality_flag'],\n",
    "        'ray_useful_signal_a':                      ['useful_signal', -1, 'observation_useful_signals', 'rayleigh_altitude_bin_useful_signal_info', -1, 'useful_signal_channel_a'],\n",
    "        'ray_useful_signal_b':                      ['useful_signal', -1, 'observation_useful_signals', 'rayleigh_altitude_bin_useful_signal_info', -1, 'useful_signal_channel_b'],\n",
    "        'ray_useful_signal_data_quality_flag':      ['useful_signal', -1, 'observation_useful_signals', 'rayleigh_altitude_bin_useful_signal_info', -1, 'data_quality_flag'],\n",
    "        'mie_us_meas' :                             ['useful_signal', -1, 'measurement_useful_signal', -1, 'mie_altitude_bin_useful_signal_info', -1, 'useful_signal'],\n",
    "        'ray_us_a_meas':                            ['useful_signal', -1, 'measurement_useful_signal', -1, 'rayleigh_altitude_bin_useful_signal_info', -1, 'useful_signal_channel_a'],\n",
    "        'ray_us_b_meas':                            ['useful_signal', -1, 'measurement_useful_signal', -1, 'rayleigh_altitude_bin_useful_signal_info', -1, 'useful_signal_channel_b'],    \n",
    "        'n':                                        ['product_confidence_data', -1, 'n'],\n",
    "        'p':                                        ['product_confidence_data', -1, 'p'],\n",
    "        'mie_integration_time':                     ['measurement', -1, 'mie_time_delays', 'bin_layer_integration_time'],\n",
    "        'ray_integration_time':                     ['measurement', -1, 'rayleigh_time_delays', 'bin_layer_integration_time'],\n",
    "        'mie_bkg_integration_time':                 ['measurement', -1, 'mie_time_delays', 'background_integration_time'],\n",
    "        'ray_bkg_integration_time':                 ['measurement', -1, 'rayleigh_time_delays', 'background_integration_time'],\n",
    "        'ray_mean_emitt_freq':                      ['product_confidence_data', -1, 'observation_pcd', 'rayleigh_mean_emitted_frequency'],\n",
    "        'ray_std_emitt_freq':                       ['product_confidence_data', -1, 'observation_pcd', 'rayleigh_emitted_frequency_std_dev'], \n",
    "        'mie_mean_emitt_freq':                      ['product_confidence_data', -1, 'observation_pcd', 'mie_mean_emitted_frequency'],\n",
    "        'mie_std_emitt_freq':                       ['product_confidence_data', -1, 'observation_pcd', 'mie_emitted_frequency_std_dev'], \n",
    "        \n",
    "        # Preliminary wind ----------------------------------------------------\n",
    "        'mie_wind':                                 ['wind_velocity', -1, 'observation_wind_profile', 'mie_altitude_bin_wind_info',-1, 'wind_velocity'],\n",
    "        'mie_wind_flag':                            ['wind_velocity', -1, 'observation_wind_profile', 'mie_altitude_bin_wind_info',-1, 'bin_quality_flag'],\n",
    "        'ray_wind':                                 ['wind_velocity', -1, 'observation_wind_profile', 'rayleigh_altitude_bin_wind_info',-1, 'wind_velocity'],\n",
    "        'ray_wind_flag':                            ['wind_velocity', -1, 'observation_wind_profile', 'rayleigh_altitude_bin_wind_info',-1, 'bin_quality_flag'],\n",
    "        'mie_wind_meas':                            ['wind_velocity', -1, 'measurement_wind_profile', -1, 'mie_altitude_bin_wind_info',-1, 'wind_velocity'],\n",
    "        'mie_wind_meas_flag':                       ['wind_velocity', -1, 'measurement_wind_profile', -1, 'mie_altitude_bin_wind_info',-1, 'bin_quality_flag'],\n",
    "        'ray_wind_meas':                            ['wind_velocity', -1, 'measurement_wind_profile', -1, 'rayleigh_altitude_bin_wind_info',-1, 'wind_velocity'],\n",
    "        'ray_wind_meas_flag':                       ['wind_velocity', -1, 'measurement_wind_profile', -1, 'rayleigh_altitude_bin_wind_info',-1, 'bin_quality_flag'],\n",
    "        'LOS_flag':                                 ['wind_velocity', -1, 'line_of_sight_wind_flag'],\n",
    "        # SNR -----------------------------------------------------------------\n",
    "        'ray_meas_signal_to_noise_ratio_channel_a': ['product_confidence_data', -1, 'measurement_pcd', -1,'meas_alt_bin_pcd', -1, 'rayleigh_signal_to_noise_ratio_channel_a'],\n",
    "        'ray_meas_signal_to_noise_ratio_channel_b': ['product_confidence_data', -1, 'measurement_pcd', -1,'meas_alt_bin_pcd', -1, 'rayleigh_signal_to_noise_ratio_channel_b'],\n",
    "        'mie_meas_signal_to_noise_ratio':           ['product_confidence_data', -1, 'measurement_pcd', -1,'meas_alt_bin_pcd', -1, 'mie_signal_to_noise_ratio'],\n",
    "        'ray_obs_signal_to_noise_ratio_channel_a':  ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'rayleigh_signal_to_noise_ratio_channel_a'],\n",
    "        'ray_obs_signal_to_noise_ratio_channel_b':  ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'rayleigh_signal_to_noise_ratio_channel_b'],\n",
    "        'mie_obs_signal_to_noise_ratio':            ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'mie_signal_to_noise_ratio'],\n",
    "    \n",
    "        'mie_refined_scattering_ratio':             ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'refined_scattering_ratio_mie'],\n",
    "        'mie_refined_signal_to_noise_ratio':        ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'refined_mie_signal_to_noise_ratio'],\n",
    "        'mie_scattering_ratio':                     ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'scattering_ratio_mie'],\n",
    "        #'mie_refined_SR_SNR_flag':                  ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'Refined_SR_SNR_Data_Quality_Flag'],\n",
    "        'mie_refined_scattering_ratio_measurement': ['product_confidence_data', -1, 'measurement_pcd', -1, 'meas_alt_bin_pcd', -1, 'refined_scattering_ratio_mie'],\n",
    "        #'mie_refined_SR_SNR_meas_flag':             ['product_confidence_data', -1, 'measurement_pcd', -1, 'meas_alt_bin_pcd', -1, 'Refined_SR_SNR_Data_Quality_Flag'],\n",
    "        'mie_core_resiudal_error':                  ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'mie_core_characteristic','residual_error'],\n",
    "        'mie_core_residual_error_meas':             ['product_confidence_data', -1, 'measurement_pcd', -1, 'meas_alt_bin_pcd', -1, 'mie_core_characteristic','residual_error'],\n",
    "        'mie_core_resiudal_error_flag':             ['product_confidence_data', -1, 'observation_pcd', 'observation_alt_bin_pcd', -1, 'mie_core_characteristic','error_flag'],\n",
    "        'mie_refined_SNR_ratio_meas':               ['product_confidence_data', -1, 'measurement_pcd', -1, 'meas_alt_bin_pcd', -1, 'refined_mie_signal_to_noise_ratio'],\n",
    "        'ray_ground_corr_velocity':                 ['ground_wind_detection', -1, 'rayleigh_ground_correction_velocity'],\n",
    "        'mie_ground_corr_velocity':                 ['ground_wind_detection', -1, 'mie_ground_correction_velocity'],\n",
    "        'updated_mie_ground_correction_velocity':   ['ground_wind_detection', -1, 'updated_mie_ground_correction_velocity'],\n",
    "        'updated_ray_ground_correction_velocity':   ['ground_wind_detection', -1, 'updated_rayleigh_ground_correction_velocity'],\n",
    "        'mie_ground_useful_signal':                 ['ground_wind_detection', -1, 'mie_ground_useful_signal'],\n",
    "        'rayleigh_ground_useful_signal':            ['ground_wind_detection', -1, 'rayleigh_ground_useful_signal'],\n",
    "       \n",
    "    }\n",
    "\n",
    "\n",
    "    def ray_mie_signals_observation(self):\n",
    "        \n",
    "        self.file['start_of_observation_time'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['start_of_observation_time']))\n",
    "        self.file['time'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['time']))\n",
    "        self.file['time_str'] = coda.time_to_string(self.file['time'].values) # [datetime.utcfromtimestamp(int(t) + datetime(2000, 1, 1, 0, 0, 0).timestamp()).strftime('%Y%m%d %H:%M:%S') for t in self.file['time']]\n",
    "        self.file['mie_longitude'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['mie_longitude'])))\n",
    "        self.file['ray_longitude'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_longitude'])))\n",
    "        self.file['longitude_of_DEM_intersection'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['longitude_of_DEM_intersection']))\n",
    "        self.file['latitude_of_DEM_intersection'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['latitude_of_DEM_intersection']))\n",
    "        self.file['argument_of_latitude'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['argument_of_latitude_of_DEM_intersection']))\n",
    "        self.file['altitude_of_DEM_intersection'] = (['obs'], coda.fetch(self.cf, *self.L1B_LOCATIONS['altitude_of_DEM_intersection']))\n",
    "        self.file['mie_altitude'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['mie_altitude'])))\n",
    "        self.file['ray_altitude'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_altitude'])))\n",
    "        self.file['mie_range'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['mie_range'])))\n",
    "        self.file['ray_range'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_range'])))\n",
    "        self.file['ray_useful_signal_a'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_useful_signal_a'])))\n",
    "        self.file['ray_useful_signal_b'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_useful_signal_b'])))\n",
    "        self.file['ray_useful_signal_data_quality_flag'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['ray_useful_signal_data_quality_flag'])))\n",
    "        self.file['mie_useful_signal'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['mie_useful_signal'])))\n",
    "        self.file['mie_useful_signal_data_quality_flag'] = (['obs', 'layer25'], np.vstack(coda.fetch(self.cf, *self.L1B_LOCATIONS['mie_useful_signal_data_quality_flag'])))\n",
    "        # ... add or delete parameters\n",
    "        return self.file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cfa93",
   "metadata": {},
   "source": [
    "### Using the STAC API to query the ESA MAAP stac catalog\n",
    "While the discovery of data (querying the ESA MAAP catalogue) does not require any authentication or authorization, accessing the data requires a token generated with an authorized eoiam account (EO Sign in) to verify the user. \n",
    "\n",
    "Currently this token is valid for 12 h, in the near future this token will be longer-lasting and a refresh option to enable M2M processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the STAC API of the ESA MAAP catalogue\n",
    "catalog_url = 'https://catalog.maap.eo.esa.int/catalogue/'\n",
    "catalog = Client.open(catalog_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65beccf0",
   "metadata": {},
   "source": [
    "The **first** step of finding data is to select the collection. For AEOLUS, ESA MAAP hosts the following 12 collections: \n",
    "\n",
    "**L0 Products** \n",
    "* AeolusL0ProductsB16\n",
    "\n",
    "**L1 Products**\n",
    "* AeolusL1AProducts\n",
    "* AeolusL1ANetCDFProducts\n",
    "* AeolusL1BProducts\n",
    "* AeolusEOLL1BProducts\n",
    "\n",
    "**L2 Products**\n",
    "* AeolusL2AProducts\n",
    "* AeolusEOLL2AProducts\n",
    "* AeolusL2BProducts\n",
    "* AeolusEOLL2BProducts\n",
    "* AeolusL2BBUFRProducts\n",
    "* AeolusEOLL2CProducts\n",
    "\n",
    "**Other**\n",
    "* AeolusAdditionalProducts \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266510c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select collection\n",
    "AE_COLLECTION = ['AeolusL1BProducts']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1035af",
   "metadata": {},
   "source": [
    "The **second** step is to further narrow down your search: \n",
    "\n",
    "**Datetime** represents the temporal coverage of the data. None can be used for both start and end to indicated unbounded queries.  \n",
    "\n",
    "**bbox** is defined by the bottom left corner (longmin latmin) and the top right corner coordinates (longmax latmax). \n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "**Filter** – allows you to search based on different metadata parameters.  \n",
    "To understand which queryables exist, you can visit:  \n",
    "`https://catalog.maap.eo.esa.int/catalogue/collections/<insertcollectionname>/queryables`\n",
    "\n",
    "This URL shows the available queryable fields for a given collection. \n",
    "\n",
    "On top of the spatial (bbox) and temporal (datetime) filters,  you can build queries with filters such as these: \n",
    "* Acquisition type, \n",
    "* Processing Date, Creation Date, Modification Date\n",
    "* Instrument,\n",
    "* Platform,\n",
    "* Orbit number,\n",
    "* Processing center, \n",
    "* Item ID,\n",
    "* Product version, \n",
    "* Processing level,\n",
    "* Sensor type, \n",
    "* Product status,\n",
    "* Processor name,\n",
    "* Sensor mode,\n",
    "* Product type \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=AE_COLLECTION, \n",
    "    filter=\"processingCenter = 'APF'\", \n",
    "    datetime = ['2023-01-29T00:00:00Z', None],\n",
    "    bbox = [0, -20, 10, -10],\n",
    "    method = 'GET', # This is necessary \n",
    "    max_items=5  # Adjust as needed\n",
    ")\n",
    "\n",
    "items = list(search.items())\n",
    "print(f\"Accessing {len(items)} items (limited by max_items).\")\n",
    "print(f\"{search.matched()} items found that matched the query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542fa58",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### What Are Assets?\n",
    "\n",
    "In a STAC catalog, **assets** are the individual files linked to a catalog item — such as imagery, metadata, thumbnails, or masks.  \n",
    "Exploring assets helps you understand what data products are available for download or analysis.\n",
    "\n",
    "> 🔍 This step is optional but useful for discovering the structure and content of your selected product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first item only\n",
    "item = items[0]\n",
    "\n",
    "print(f\"Item 0 — ID: {item.id if hasattr(item, 'id') else item.get('id')}\")\n",
    "\n",
    "# If item is a pystac.Item\n",
    "try:\n",
    "    assets = item.assets\n",
    "except AttributeError:\n",
    "    # If item is a dict\n",
    "    assets = item.get(\"assets\", {})\n",
    "\n",
    "if assets:\n",
    "    print(\"  Available asset keys:\")\n",
    "    for key in assets.keys():\n",
    "        print(\"   -\", key)\n",
    "else:\n",
    "    print(\"  No assets found for this item.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56312a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of asset keys and their URLs\n",
    "asset_data = []\n",
    "if assets:\n",
    "    for key, asset in assets.items():\n",
    "        href = asset.href if hasattr(asset, 'href') else asset.get('href')\n",
    "        asset_data.append({'Asset Key': key, 'URL': href})\n",
    "else:\n",
    "    print(\"No assets found for this item.\")\n",
    "\n",
    "# Create a DataFrame for visualization and access\n",
    "df_assets = pd.DataFrame(asset_data)\n",
    "df_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a76dd8",
   "metadata": {},
   "source": [
    "**Tips**: \n",
    "\n",
    "- **Want a quick look?** Use the asset thumbnail to preview the data.\n",
    "- **Want the full product?** the asset key product points to the full zipped product.\n",
    "- **Need to analyze?**  — `enclosure_2` contains the `.DBL` file, Work with `enclosure_1`, which contains the `.HDR` file\n",
    "- **Don't need everything?** Avoid the .zip unless you really need to download all files.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966d5b2",
   "metadata": {},
   "source": [
    "### Quicklook of the data\n",
    "\n",
    "You don't need to authenticate or authorize to preview the data.  \n",
    "By referencing the `thumbnail` asset, you're accessing a remote URL where a quicklook image of the product is stored.  \n",
    "This provides a fast and convenient way to visually inspect the data before downloading or processing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f15cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_url = df_assets[df_assets[\"Asset Key\"] == \"thumbnail\"][\"URL\"].values[0]\n",
    "display(Image(url=ql_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c49686d",
   "metadata": {},
   "source": [
    "### Token\n",
    "Paste your token below or save it in a token.txt\n",
    "\n",
    "You can generate the token [here](https://portal.maap.eo.esa.int/ini/services/auth/token/index.php). \n",
    "\n",
    "Remember that it is currently only valid for 12 h! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb94738",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pathlib.Path(\"token_yourname.txt\").exists():\n",
    "  print(\"Using token from .txt\")\n",
    "  with open(\"token_yourname.txt\",\"rt\") as f:\n",
    "    token = f.read().strip().replace(\"\\n\",\"\")\n",
    "    print(token)\n",
    "else:\n",
    "  print(\"No token found. Please provide a valid token in token_yourname.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43fde8",
   "metadata": {},
   "source": [
    "### Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1b_url = df_assets[df_assets[\"Asset Key\"] == \"enclosure_2\"][\"URL\"].values[0]\n",
    "print(l1b_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"https\", headers={\"Authorization\": f\"Bearer \" + token})\n",
    "\n",
    "# Create a temporary file for CODA\n",
    "# Instead of reading the whole file at once (f.read(), we read chunks repeatedly in a loop)\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".DBL\") as tmp_file:\n",
    "    with fs.open(l1b_url, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(8 * 2**20)  # Using 8 MB Chunks\n",
    "            if not chunk:\n",
    "                break\n",
    "            tmp_file.write(chunk)\n",
    "    tmp_path = tmp_file.name\n",
    "\n",
    "try:\n",
    "    product = coda.open(tmp_path)\n",
    "    dataReader = L1b_reader(product)\n",
    "    ds = dataReader.ray_mie_signals_observation()\n",
    "    \n",
    "finally:\n",
    "    # Cleanup the temporary file\n",
    "    coda.close(product)\n",
    "    os.remove(tmp_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc36068",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do something with the dataset \n",
    "ds[\"mie_useful_signal\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca7280",
   "metadata": {},
   "source": [
    "## Downloading data \n",
    "You can also use your token and the url to download data and not just stream it / load it into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d34352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_with_bearer_token(url, token, disable_bar=False):\n",
    "  \"\"\"\n",
    "  Downloads a file from a given URL using a Bearer token.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes\n",
    "    file_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "    chunk_size = 8 * 1024 * 1024 # Byes - 1MiB\n",
    "    file_path = url.rsplit('/', 1)[-1] \n",
    "    print(file_path)\n",
    "    with open(file_path, \"wb\") as f, tqdm(\n",
    "        desc=file_path,\n",
    "        total=file_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "        disable=disable_bar,\n",
    "      ) as bar:\n",
    "      for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "        read_size=f.write(chunk)\n",
    "        bar.update(read_size)\n",
    "\n",
    "    if (disable_bar): \n",
    "      print(f\"File downloaded successfully to {file_path}\")\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f306f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to any URL of your choice in the STAC assets\n",
    "download_file_with_bearer_token(l1b_url, token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
